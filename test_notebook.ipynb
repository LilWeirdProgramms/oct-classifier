{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "100/100 [==============================] - 1s 2ms/step - loss: 1.2092 - sparse_categorical_accuracy: 0.6751\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.3896 - sparse_categorical_accuracy: 0.8880\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.3540 - sparse_categorical_accuracy: 0.8945\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f2655fef580>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocess the data (these are NumPy arrays)\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")\n",
    "\n",
    "# Reserve 10,000 samples for validation\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]\n",
    "\n",
    "def get_uncompiled_model():\n",
    "    inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "def get_compiled_model():\n",
    "    model = get_uncompiled_model()\n",
    "    model.compile(\n",
    "        optimizer=\"rmsprop\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"sparse_categorical_accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Only use the 100 batches per epoch (that's 64 * 100 samples)\n",
    "model.fit(train_dataset, epochs=3, steps_per_epoch=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0. 1. 8. 6. 5. 5. 7. 5. 1. 7. 5. 9. 8. 4. 6. 2. 4. 0. 0. 6. 8. 4. 3. 6.\n",
      " 5. 3. 7. 5. 0. 9. 0. 5. 1. 0. 3. 8. 6. 4. 1. 9. 1. 4. 0. 2. 9. 4. 1. 9.\n",
      " 6. 9. 7. 3. 8. 8. 9. 2. 4. 3. 9. 7. 8. 8. 6. 6.], shape=(64,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "for elem in train_dataset:\n",
    "    print(elem[1])\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1308 - sparse_categorical_accuracy: 0.9625\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1481 - sparse_categorical_accuracy: 0.9542\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1282 - sparse_categorical_accuracy: 0.9620\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=3, steps_per_epoch=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(64, 784), dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>, <tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
      "array([7., 3., 0., 2., 8., 2., 4., 4., 0., 9., 7., 0., 6., 9., 7., 0., 9.,\n",
      "       7., 0., 9., 1., 8., 0., 5., 1., 5., 5., 6., 7., 7., 0., 2., 7., 5.,\n",
      "       1., 9., 6., 6., 3., 0., 9., 2., 5., 1., 7., 5., 4., 0., 1., 1., 7.,\n",
      "       2., 7., 9., 5., 9., 9., 3., 5., 8., 8., 7., 4., 1.], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "for elem in train_dataset:\n",
    "    print(elem)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7f26000871f0>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(elem[0][0,:].numpy().reshape(28, 28), cmap=\"Greys\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(784,), dtype=float32, numpy=\narray([0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.27450982,\n       0.96862745, 0.19607843, 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.05490196, 0.92156863, 0.972549  , 0.19607843,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.06666667, 0.72156864,\n       0.99607843, 0.63529414, 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.30588236, 0.99607843, 0.99607843, 0.4862745 ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.30588236,\n       0.99607843, 0.63529414, 0.09019608, 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.5019608 , 0.99607843, 0.14509805,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.67058825,\n       0.9882353 , 0.9882353 , 0.09019608, 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.01568628, 0.7254902 , 0.99607843, 0.5803922 ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.24313726,\n       0.99607843, 0.99607843, 0.16078432, 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.06666667, 0.8862745 , 1.        , 0.78431374,\n       0.05098039, 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.09411765,\n       0.99607843, 0.99607843, 0.3372549 , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.49019608, 0.99607843, 0.627451  ,\n       0.03921569, 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.02352941,\n       0.9607843 , 0.99607843, 0.3019608 , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.48235294, 0.99607843, 0.99215686,\n       0.28627452, 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.49411765, 0.99607843, 0.8352941 , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.79607844, 0.99607843,\n       0.5294118 , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.95686275, 0.92941177, 0.10196079, 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.49019608, 0.9882353 ,\n       0.90588236, 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.8862745 , 0.99607843, 0.90588236, 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.6666667 ,\n       0.99607843, 0.47058824, 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        ], dtype=float32)>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elem[0][0,:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(64,), dtype=float32, numpy=\narray([1., 4., 4., 9., 7., 6., 8., 1., 0., 5., 1., 4., 9., 9., 0., 3., 9.,\n       6., 2., 3., 8., 1., 3., 1., 4., 4., 2., 2., 2., 7., 1., 5., 1., 7.,\n       7., 7., 9., 2., 6., 0., 4., 5., 6., 8., 6., 8., 9., 9., 3., 2., 6.,\n       7., 0., 1., 4., 0., 2., 0., 4., 4., 3., 5., 0., 9.], dtype=float32)>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elem[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "outer_list = [[1,0,1],\n",
    " [1,1,1],\n",
    " [0,0,0]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "[[True, False, True], [True, True, True], [False, False, False]]"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[bool(inner_entry) for inner_entry in inner_list] for inner_list in outer_list]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def print_bag():\n",
    "    model.evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}