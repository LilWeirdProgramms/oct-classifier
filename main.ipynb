{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-21 10:11:39.045030: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-02-21 10:11:41.237493: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2022-02-21 10:11:41.237615: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2022-02-21 10:11:41.238744: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-02-21 10:11:41.942382: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 2 GPUs\n",
      "2022-02-21 10:11:41.943225: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so.10.1\n",
      "2022-02-21 10:11:41.944450: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2022-02-21 10:11:41.944606: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed\n",
      "2022-02-21 10:11:41.945840: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2022-02-21 10:11:41.945860: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2022-02-21 10:11:41.945950: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2022-02-21 10:11:41.946006: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "from importlib import reload\n",
    "import InputList\n",
    "import BinaryReader\n",
    "import Preprocessor\n",
    "import models\n",
    "import Callbacks\n",
    "import InputListUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<module 'InputListUtils' from '/home/juliusmlcaesar/PycharmProjects/oct-classifier/InputListUtils.py'>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(InputListUtils)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "InputListUtils.generate_diabetic_files_list()\n",
    "tr_files = InputList.diabetic_training_files + InputList.healthy_training_files\n",
    "len(tr_files)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 10:23:07.593822: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-02-17 10:23:07.596532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:06:00.0 name: TITAN RTX computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2022-02-17 10:23:07.598900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:21:00.0 name: TITAN RTX computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2022-02-17 10:23:07.598952: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-02-17 10:23:07.601131: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-02-17 10:23:07.601191: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-02-17 10:23:07.603447: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-02-17 10:23:07.603797: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-02-17 10:23:07.606096: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-02-17 10:23:07.607139: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-02-17 10:23:07.610674: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-02-17 10:23:07.616779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n",
      "[('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D95/rechts/raw_1536x2048x2045x2_5217.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D60 FU1/links/raw_1536x2048x2045x2_7051.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D73/links/raw_1536x2048x2045x2_29875.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D62/links/raw_1536x2048x2045x2_7930.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D105/links/raw_1536x2048x2045x2_29122.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D77/links/raw_1536x2048x2045x2_3140.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D92/links/raw_1536x2048x2045x2_21336.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D63/links/raw_1536x2048x2045x2_29802.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D77/rechts/raw_1536x2048x2045x2_2637.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D48/rechts/raw_1536x2048x2045x2_31937.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D41/rechts/raw_1536x2048x2045x2_8906.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D48/rechts/raw_1536x2048x2045x2_31542.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D74/rechts/raw_1536x2048x2045x2_22396.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D75/links/raw_1536x2048x2045x2_25595.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D90/rechts/raw_1536x2048x2045x2_10013.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D65/links/raw_1536x2048x2045x2_27359.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D88/links/raw_1536x2048x2045x2_19374.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D84/rechts/raw_1536x2048x2045x2_15007.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D45/rechts/raw_1536x2048x2045x2_11180.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D103/links/raw_1536x2048x2045x2_18810.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D57/rechts/raw_1536x2048x2045x2_20400.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D110/links/raw_1536x2048x2045x2_11677.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D79/rechts/raw_1536x2048x2045x2_18832.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D100/links/raw_1536x2048x2045x2_2159.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D50/links/raw_1536x2048x2045x2_29971.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D104/links/raw_1536x2048x2045x2_21024.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D69/rechts/raw_1536x2048x2045x2_1857.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D43/FU1/raw_1536x2048x2045x2_28898.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/H4/raw_1536x2048x2045x2_13025.bin', 0), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D71/rechts/raw_1536x2048x2045x2_2375.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D47/links/raw_1536x2048x2045x2_11720.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D98/links/raw_1536x2048x2045x2_17468.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D91/rechts/raw_1536x2048x2045x2_32132.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D80/rechts/raw_1536x2048x2045x2_28684.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D72/links/raw_1536x2048x2045x2_9468.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D103/links/raw_1536x2048x2045x2_19156.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D85/rechts/raw_1536x2048x2045x2_19200.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D103/rechts/raw_1536x2048x2045x2_19787.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D95/links/raw_1536x2048x2045x2_5789.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D76/links/raw_1536x2048x2045x2_6348.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D58/rechts/raw_1536x2048x2045x2_1337.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D105/rechts/raw_1536x2048x2045x2_28133.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D42/links/raw_1536x2048x2045x2_17221.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D49/left/raw_1536x2048x2045x2_8449.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D50/links/raw_1536x2048x2045x2_30271.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D46/rechts/raw_1536x2048x2045x2_20039.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D59/rechts/raw_1536x2048x2045x2_18502.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D75/links/raw_1536x2048x2045x2_25395.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D87/rechts/raw_1536x2048x2045x2_30737.bin', 1), ('/mnt/p_Zeiss/Projects/UWF OCTA/Clinical data/MOON1/D60/RIGHT/raw_1536x2048x2045x2_12122.bin', 1)]\n",
      "WARNING:tensorflow:AutoGraph could not transform <function BinaryReader.create_dataset.<locals>.<lambda> at 0x7fd2b4099af0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function BinaryReader.create_dataset.<locals>.<lambda> at 0x7fd2b4099af0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function BinaryReader.create_dataset.<locals>.<lambda> at 0x7fd2b40cfb80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function BinaryReader.create_dataset.<locals>.<lambda> at 0x7fd2b40cfb80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 10:23:08.223247: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-17 10:23:08.553372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:06:00.0 name: TITAN RTX computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2022-02-17 10:23:08.554816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:21:00.0 name: TITAN RTX computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2022-02-17 10:23:08.554863: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-02-17 10:23:08.554905: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-02-17 10:23:08.554925: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-02-17 10:23:08.554962: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-02-17 10:23:08.554981: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-02-17 10:23:08.554996: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-02-17 10:23:08.555009: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-02-17 10:23:08.555022: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-02-17 10:23:08.560803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2022-02-17 10:23:08.560845: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-02-17 10:23:09.690472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-02-17 10:23:09.690511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2022-02-17 10:23:09.690519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y \n",
      "2022-02-17 10:23:09.690523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N \n",
      "2022-02-17 10:23:09.696953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21341 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:06:00.0, compute capability: 7.5)\n",
      "2022-02-17 10:23:09.700764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 22178 MB memory) -> physical GPU (device: 1, name: TITAN RTX, pci bus id: 0000:21:00.0, compute capability: 7.5)\n",
      "2022-02-17 10:23:09.701015: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "reader = BinaryReader.BinaryReader()  # TODO: Normalizer\n",
    "training_dataset, validation_dataset = reader.create_training_datasets(tr_files)\n",
    "preprocesser = Preprocessor.Preprocessor(training_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "{0: 13.666666666666666, 1: 0.5189873417721519}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = len(InputList.diabetic_training_files)\n",
    "b = len(InputList.healthy_training_files)\n",
    "class_weights = {0: (1/b) * (a+b)/2, 1:(1/a) * (a+b)/2}\n",
    "class_weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n",
      "Creating Normalization Layer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 10:23:20.914343: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-02-17 10:23:20.933614: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2399700000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1536, 102, 102, 1 0         \n",
      "_________________________________________________________________\n",
      "normalization (Normalization (None, 1536, 102, 102, 1) 3         \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              (None, 1536, 102, 102, 32 896       \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 768, 51, 51, 32)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 768, 51, 51, 64)   55360     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 384, 25, 25, 64)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 384, 25, 25, 96)   165984    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 192, 12, 12, 96)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 192, 12, 12, 128)  331904    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 96, 6, 6, 128)     0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 442368)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 442369    \n",
      "=================================================================\n",
      "Total params: 996,516\n",
      "Trainable params: 996,513\n",
      "Non-trainable params: 3\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 10:26:12.749911: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"ParallelInterleaveDatasetV4/_7\"\n",
      "op: \"ParallelInterleaveDatasetV4\"\n",
      "input: \"TensorSliceDataset/_1\"\n",
      "input: \"Const/_2\"\n",
      "input: \"Const/_3\"\n",
      "input: \"Const/_10\"\n",
      "input: \"Const/_5\"\n",
      "input: \"Const/_6\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"deterministic\"\n",
      "  value {\n",
      "    s: \"false\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_interleave_lambda_43\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 1536\n",
      "        }\n",
      "        dim {\n",
      "          size: 102\n",
      "        }\n",
      "        dim {\n",
      "          size: 102\n",
      "        }\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_UINT16\n",
      "      type: DT_UINT8\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 10:26:12.990505: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2022-02-17 10:26:12.990554: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2022-02-17 10:26:12.990861: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1415] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 10:26:16.533228: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-02-17 10:27:05.887129: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     20/Unknown - 202s 3s/step - loss: 9.9611 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 10:29:35.310947: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
      "2022-02-17 10:29:35.397791: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:228]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2022-02-17 10:29:35.431351: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2022-02-17 10:29:35.479671: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: logs/20220217-102255/train/plugins/profile/2022_02_17_10_29_35\n",
      "2022-02-17 10:29:35.512759: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to logs/20220217-102255/train/plugins/profile/2022_02_17_10_29_35/hyperion-vie.trace.json.gz\n",
      "2022-02-17 10:29:35.662034: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: logs/20220217-102255/train/plugins/profile/2022_02_17_10_29_35\n",
      "2022-02-17 10:29:35.682503: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to logs/20220217-102255/train/plugins/profile/2022_02_17_10_29_35/hyperion-vie.memory_profile.json.gz\n",
      "2022-02-17 10:29:35.684367: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/20220217-102255/train/plugins/profile/2022_02_17_10_29_35Dumped tool data for xplane.pb to logs/20220217-102255/train/plugins/profile/2022_02_17_10_29_35/hyperion-vie.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/20220217-102255/train/plugins/profile/2022_02_17_10_29_35/hyperion-vie.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/20220217-102255/train/plugins/profile/2022_02_17_10_29_35/hyperion-vie.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/20220217-102255/train/plugins/profile/2022_02_17_10_29_35/hyperion-vie.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/20220217-102255/train/plugins/profile/2022_02_17_10_29_35/hyperion-vie.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  17437/Unknown - 82777s 5s/step - loss: 12.7600"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_1461/4234533567.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     12\u001B[0m     \u001B[0moptions\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_distribute\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mauto_shard_policy\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mAutoShardPolicy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mOFF\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m     history = model.fit(\n\u001B[0m\u001B[1;32m     15\u001B[0m         \u001B[0mpreprocesser\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m         \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/octClassifier/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1098\u001B[0m                 _r=1):\n\u001B[1;32m   1099\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1100\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1101\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1102\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/octClassifier/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    826\u001B[0m     \u001B[0mtracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    827\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mtrace\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTrace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_name\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtm\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 828\u001B[0;31m       \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    829\u001B[0m       \u001B[0mcompiler\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"xla\"\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_experimental_compile\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m\"nonXla\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    830\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/octClassifier/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    853\u001B[0m       \u001B[0;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    854\u001B[0m       \u001B[0;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 855\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=not-callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    856\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    857\u001B[0m       \u001B[0;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/octClassifier/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2940\u001B[0m       (graph_function,\n\u001B[1;32m   2941\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0;32m-> 2942\u001B[0;31m     return graph_function._call_flat(\n\u001B[0m\u001B[1;32m   2943\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[1;32m   2944\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/octClassifier/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1916\u001B[0m         and executing_eagerly):\n\u001B[1;32m   1917\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1918\u001B[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[1;32m   1919\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[1;32m   1920\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[0;32m~/miniconda3/envs/octClassifier/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    553\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    554\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 555\u001B[0;31m           outputs = execute.execute(\n\u001B[0m\u001B[1;32m    556\u001B[0m               \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    557\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/octClassifier/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     57\u001B[0m   \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 59\u001B[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[1;32m     60\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[1;32m     61\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    print(\"Creating Normalization Layer:\")\n",
    "    normalization_layer = preprocesser.normalize_layer()\n",
    "\n",
    "    model = models.RawClassifier().model()(training_dataset.element_spec[0].shape, normalization_layer, reconstruction=False)\n",
    "\n",
    "    options = tf.data.Options()\n",
    "    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
    "\n",
    "    history = model.fit(\n",
    "        preprocesser.batch(3),\n",
    "        epochs=10,\n",
    "        validation_data=Preprocessor.Preprocessor(validation_dataset).batch(3),\n",
    "        callbacks=Callbacks.my_callbacks,\n",
    "        class_weight=class_weights,\n",
    "        use_multiprocessing=True\n",
    "    )\n",
    "    model.save('savedModels/first')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "expected = 26133\n",
    "expected_time = 26133 * 4 # sekunden -> 30 Stunden pro Epoche :("
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#normalization_weights = normalization_layer.get_weights()\n",
    "#print(\"Before:\" + str(normalization_weights))\n",
    "# normalization_weights_path = \"results/normalization.npy\"\n",
    "# #np.save(normalization_weights_path, normalization_weights)\n",
    "# normalization_layer.set_weights(np.load(normalization_weights_path))\n",
    "# print(\"After\" + str(normalization_layer.get_weights()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 09:26:48.837202: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Assets written to: savedModels/first_with_all_data/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('savedModels/first_with_all_data')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}