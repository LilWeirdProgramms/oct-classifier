{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 11:28:37.509589: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "from importlib import reload\n",
    "import InputList\n",
    "import BinaryReader\n",
    "import Preprocessor\n",
    "import models\n",
    "import Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "<module 'InputList' from '/home/julius/dataspellprojects/oct-classifier/InputList.py'>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(InputList)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make this such that it can be used for prediction and training pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Warning: Only files of one Dataset are present in the Validation Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 11:28:40.965139: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-02-08 11:28:40.965533: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-02-08 11:28:40.965556: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-08 11:28:40.965586: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (zeissstudent1): /proc/driver/nvidia/version does not exist\n",
      "2022-02-08 11:28:40.998990: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-08 11:28:40.999436: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "reader = BinaryReader.BinaryReader()  # TODO: Normalizer\n",
    "training_dataset, validation_dataset = reader.create_training_datasets(InputList.training_files)\n",
    "preprocesser = Preprocessor.Preprocessor(training_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Normalization Layer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 11:28:48.953530: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-02-08 11:28:48.974725: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2899885000 Hz\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating Normalization Layer:\")\n",
    "normalization_layer = preprocesser.normalize_layer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:[32762.3, 4103221.0, 9891840]\n",
      "After[32762.3, 4103221.0, 9891840]\n"
     ]
    }
   ],
   "source": [
    "normalization_weights = normalization_layer.get_weights()\n",
    "print(\"Before:\" + str(normalization_weights))\n",
    "normalization_weights_path = \"results/normalization.npy\"\n",
    "np.save(normalization_weights_path, normalization_weights)\n",
    "normalization_layer.set_weights(np.load(normalization_weights_path))\n",
    "print(\"After\" + str(normalization_weights))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "normalization_layer.set_weights(np.array([32743.002, 5470130.0, 25706913792]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1536, 23, 28, 1)] 0         \n",
      "_________________________________________________________________\n",
      "normalization (Normalization (None, 1536, 23, 28, 1)   3         \n",
      "_________________________________________________________________\n",
      "permute (Permute)            (None, 1, 23, 28, 1536)   0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1, 23, 28, 768)    1179648   \n",
      "_________________________________________________________________\n",
      "permute_1 (Permute)          (None, 768, 23, 28, 1)    0         \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              (None, 768, 23, 28, 32)   896       \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 384, 11, 14, 32)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 384, 11, 14, 64)   55360     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 192, 5, 7, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 192, 5, 7, 96)     165984    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 96, 2, 3, 96)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 96, 2, 3, 128)     331904    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 48, 1, 1, 128)     0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6144)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 12288     \n",
      "=================================================================\n",
      "Total params: 1,746,083\n",
      "Trainable params: 1,746,080\n",
      "Non-trainable params: 3\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.classiRaw3D(training_dataset.element_spec[0].shape, normalization_layer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "2599/2599 [==============================] - ETA: 0s - loss: 7.1100e-11 - sparse_categorical_crossentropy: 7.1100e-11"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    preprocesser.batch(20),\n",
    "    epochs=30,\n",
    "    validation_data=Preprocessor.Preprocessor(validation_dataset).batch(20),\n",
    "    callbacks=Callbacks.my_callbacks\n",
    ")\n",
    "model.save('savedModels/first')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 1536, 23, 28, 1)] 0         \n",
      "_________________________________________________________________\n",
      "normalization (Normalization (None, 1536, 23, 28, 1)   3         \n",
      "_________________________________________________________________\n",
      "conv3d_25 (Conv3D)           (None, 1536, 23, 28, 64)  1792      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_25 (MaxPooling (None, 768, 11, 14, 64)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_26 (Conv3D)           (None, 768, 11, 14, 128)  221312    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_26 (MaxPooling (None, 384, 5, 7, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_27 (Conv3D)           (None, 384, 5, 7, 192)    663744    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_27 (MaxPooling (None, 192, 2, 3, 192)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_28 (Conv3D)           (None, 192, 2, 3, 256)    1327360   \n",
      "_________________________________________________________________\n",
      "max_pooling3d_28 (MaxPooling (None, 96, 1, 1, 256)     0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 24576)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 49152     \n",
      "=================================================================\n",
      "Total params: 2,263,363\n",
      "Trainable params: 2,263,360\n",
      "Non-trainable params: 3\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reload(models)\n",
    "model = models.classiRaw3D(training_dataset.element_spec[0].shape, normalization_layer, reconstruction=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [
    {
     "data": {
      "text/plain": "<PrefetchDataset shapes: ((1536, 23, 28, 1), ()), types: (tf.uint16, tf.uint8)>"
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.debugging.set_log_device_placement(True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f969874a730>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"checkpoints/best_model\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='checkpoints/best_model.data-00000-of-00001' mode='r' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "with open(\"checkpoints/best_model.data-00000-of-00001\") as testi:\n",
    "    print(testi)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "print_function(Bag Number, dataset)\n",
    "\n",
    "-> In einem Bag sind 7000 Instanzen"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bag Level Model:\n",
    "\n",
    "Ich hab ganz viele Softmaxes und von denen nehm ich einfach den Max Wert"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 18:00:53.002220: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 5064622080 exceeds 10% of free system memory.\n",
      "2022-02-08 18:00:57.834422: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 5064622080 exceeds 10% of free system memory.\n",
      "2022-02-08 18:01:03.134897: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 5064622080 exceeds 10% of free system memory.\n",
      "2022-02-08 18:01:08.671641: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 5064622080 exceeds 10% of free system memory.\n",
      "2022-02-08 18:01:14.168709: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 5064622080 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "test_dataset = reader.create_test_dataset([InputList.diabetic_training_files[4]])\n",
    "output = model.predict(test_dataset.batch(20))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "prediction_file = InputList.diabetic_training_files[4]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Linearisierung:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (<PrefetchDataset shapes: ((1536, 23, 28, 1), ()), types: (tf.uint16, tf.uint8)>) with an unsupported type (<class 'tensorflow.python.data.ops.dataset_ops.PrefetchDataset'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_81613/3947652429.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mnormalized\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnormalization_layer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_dataset\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m20\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/miniconda3/envs/octClassifier/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1010\u001B[0m         with autocast_variable.enable_auto_cast_variables(\n\u001B[1;32m   1011\u001B[0m             self._compute_dtype_object):\n\u001B[0;32m-> 1012\u001B[0;31m           \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1013\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1014\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_activity_regularizer\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/octClassifier/lib/python3.9/site-packages/tensorflow/python/keras/layers/preprocessing/normalization.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m    196\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    197\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mcall\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 198\u001B[0;31m     \u001B[0minputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvert_to_tensor_v2_with_dispatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    199\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrank\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    200\u001B[0m       \u001B[0minputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0marray_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexpand_dims\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/octClassifier/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    199\u001B[0m     \u001B[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    200\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 201\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    202\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    203\u001B[0m       \u001B[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/octClassifier/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36mconvert_to_tensor_v2_with_dispatch\u001B[0;34m(value, dtype, dtype_hint, name)\u001B[0m\n\u001B[1;32m   1402\u001B[0m     \u001B[0mValueError\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mIf\u001B[0m \u001B[0mthe\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;31m`\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0ma\u001B[0m \u001B[0mtensor\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mof\u001B[0m \u001B[0mgiven\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;31m`\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mgraph\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1403\u001B[0m   \"\"\"\n\u001B[0;32m-> 1404\u001B[0;31m   return convert_to_tensor_v2(\n\u001B[0m\u001B[1;32m   1405\u001B[0m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001B[1;32m   1406\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/octClassifier/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36mconvert_to_tensor_v2\u001B[0;34m(value, dtype, dtype_hint, name)\u001B[0m\n\u001B[1;32m   1408\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mconvert_to_tensor_v2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype_hint\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1409\u001B[0m   \u001B[0;34m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1410\u001B[0;31m   return convert_to_tensor(\n\u001B[0m\u001B[1;32m   1411\u001B[0m       \u001B[0mvalue\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1412\u001B[0m       \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/octClassifier/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\u001B[0m in \u001B[0;36mwrapped\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    161\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mTrace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrace_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mtrace_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    162\u001B[0m           \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 163\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    164\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    165\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mwrapped\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/octClassifier/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36mconvert_to_tensor\u001B[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001B[0m\n\u001B[1;32m   1538\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1539\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mret\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1540\u001B[0;31m       \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconversion_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mas_ref\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mas_ref\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1541\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1542\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mret\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0mNotImplemented\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/octClassifier/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001B[0m in \u001B[0;36m_constant_tensor_conversion_function\u001B[0;34m(v, dtype, name, as_ref)\u001B[0m\n\u001B[1;32m    337\u001B[0m                                          as_ref=False):\n\u001B[1;32m    338\u001B[0m   \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mas_ref\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 339\u001B[0;31m   \u001B[0;32mreturn\u001B[0m \u001B[0mconstant\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mv\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    340\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    341\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/octClassifier/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001B[0m in \u001B[0;36mconstant\u001B[0;34m(value, dtype, shape, name)\u001B[0m\n\u001B[1;32m    262\u001B[0m     \u001B[0mValueError\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mcalled\u001B[0m \u001B[0mon\u001B[0m \u001B[0ma\u001B[0m \u001B[0msymbolic\u001B[0m \u001B[0mtensor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    263\u001B[0m   \"\"\"\n\u001B[0;32m--> 264\u001B[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001B[0m\u001B[1;32m    265\u001B[0m                         allow_broadcast=True)\n\u001B[1;32m    266\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/octClassifier/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001B[0m in \u001B[0;36m_constant_impl\u001B[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001B[0m\n\u001B[1;32m    274\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mtrace\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTrace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"tf.constant\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    275\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0m_constant_eager_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mctx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverify_shape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 276\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_constant_eager_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mctx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverify_shape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    277\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    278\u001B[0m   \u001B[0mg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_default_graph\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/octClassifier/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001B[0m in \u001B[0;36m_constant_eager_impl\u001B[0;34m(ctx, value, dtype, shape, verify_shape)\u001B[0m\n\u001B[1;32m    299\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_constant_eager_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mctx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverify_shape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    300\u001B[0m   \u001B[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 301\u001B[0;31m   \u001B[0mt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_to_eager_tensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mctx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    302\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0mshape\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    303\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/octClassifier/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001B[0m in \u001B[0;36mconvert_to_eager_tensor\u001B[0;34m(value, ctx, dtype)\u001B[0m\n\u001B[1;32m     96\u001B[0m       \u001B[0mdtype\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdtypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mas_dtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mas_datatype_enum\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     97\u001B[0m   \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 98\u001B[0;31m   \u001B[0;32mreturn\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mEagerTensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     99\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    100\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Attempt to convert a value (<PrefetchDataset shapes: ((1536, 23, 28, 1), ()), types: (tf.uint16, tf.uint8)>) with an unsupported type (<class 'tensorflow.python.data.ops.dataset_ops.PrefetchDataset'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "normalized = normalization_layer(test_dataset).batch(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.5320530e-12, 1.0000000e+00],\n       [3.6272407e-13, 1.0000000e+00],\n       [5.2061959e-14, 1.0000000e+00],\n       ...,\n       [2.7368467e-13, 1.0000000e+00],\n       [3.6967787e-13, 1.0000000e+00],\n       [4.5514542e-13, 1.0000000e+00]], dtype=float32)"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "6497"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "73*89"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "0.0"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "round(output[1,0],2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "0.0"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(output[4500,0],5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(output[:,1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[2.7189600e-12, 1.0000000e+00],\n       [3.0085756e-12, 1.0000000e+00],\n       [2.3979503e-12, 1.0000000e+00],\n       ...,\n       [1.1708659e-11, 1.0000000e+00],\n       [4.0693295e-12, 1.0000000e+00],\n       [2.3206693e-12, 1.0000000e+00]], dtype=float32)"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}